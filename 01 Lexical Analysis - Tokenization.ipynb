{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9d8b6b-fbf4-426a-ae7c-a6fa5081c2e8",
   "metadata": {},
   "source": [
    "##### Library Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5763c3d5-e599-40c3-94d4-387bbb022c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/mitu/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: spacy in /home/mitu/.local/lib/python3.10/site-packages (3.7.4)\n",
      "Requirement already satisfied: textblob in /home/mitu/.local/lib/python3.10/site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/mitu/.local/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in /home/mitu/.local/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (6.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (2.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from spacy) (59.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/mitu/.local/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/mitu/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /home/mitu/.local/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mitu/.local/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.6.20)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/mitu/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/mitu/.local/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/mitu/.local/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk spacy textblob -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dc19dcc-e639-46f1-be89-408d557be2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71954e53-4185-4d4c-8f7a-45f4f9971f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/mitu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/mitu/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/mitu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/mitu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/mitu/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package indian to /home/mitu/nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/mitu/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # tokenization\n",
    "nltk.download('stopwords') # stopwords removal\n",
    "nltk.download('averaged_perceptron_tagger') # POS tagging\n",
    "nltk.download('wordnet') # wordnet database and lemmatization\n",
    "nltk.download('omw-1.4') # stemming\n",
    "nltk.download('indian') # Indian language POS tagging\n",
    "nltk.download('maxent_ne_chunker') # chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5476a7-8cf3-450c-904f-5a27d33918d9",
   "metadata": {},
   "source": [
    "##### Sample Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a38e5eef-754c-4290-99a6-05694f8e5b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'They told that their ages are 25, 27 and 31 respectively.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bff21a81-4d81-4360-86c1-f5f3b138e680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average of ages mentioned in the above sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c8e8763-4315-451d-9948-cf5e49ea6f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages = []\n",
    "for word in sent.split():\n",
    "    if word.isdigit():\n",
    "        ages.append(int(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4a2fbe6-0542-416f-a0cc-b94ab293e072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.666666666666668"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ages) / len(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66bff1a2-2366-4576-b1f2-c8c88b5ef41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.666666666666668"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages = [int(word) for word in sent.split() if word.isdigit()]\n",
    "sum(ages) / len(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4087bd2-6c7c-4602-a4be-969e2093a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0a2edfa-00e0-4e7e-bef6-ee36e31d3227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.666666666666668"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([int(word) for word in sent.split() if word.isdigit()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff200e5-3065-4c88-b5d7-e55e210e10c2",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5f6b2fb-5d8d-45fd-936a-d7afce78d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Hello friends! How are you? Welcome to Python Programming.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04cb63c3-2a25-4349-ace2-8fc3085be39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the functions\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8abe2d2-09d8-452e-8e5d-85abf418ced6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello friends!', 'How are you?', 'Welcome to Python Programming.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# segmentation\n",
    "sent_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "50956dcd-135e-4f50-a02d-30da5eca3b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " '.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a9a0344-be39-46c3-8c79-255ca7c016ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find percentage of punctuation symbols present in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc42a316-2176-4385-95ac-6d37e0d4ed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_count = len([word for word in word_tokenize(sent) if not word.isalnum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b5538771-b5ef-4cdc-a54f-c4614cbae5c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_count / len(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63818b7d-3143-4d4d-8241-6ae375906de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bca132e4-6d06-42b1-b0de-6d27037fb075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f02df47f-17f0-4102-95a3-1bbc07c19940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof('=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cab5392d-a426-42e5-952e-0146163b312b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function getsizeof in module sys:\n",
      "\n",
      "getsizeof(...)\n",
      "    getsizeof(object [, default]) -> int\n",
      "    \n",
      "    Return the size of object in bytes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sys.getsizeof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a0a1b9e2-555b-4c3d-b610-31bb90674614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char = 'abcdefghih'\n",
    "sys.getsizeof(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1c3f1b74-676a-4df8-8cc7-18b95394ef1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ࠓ'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(2067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62355a95-b549-4e0d-a99a-15f2093d543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "char = '\\u0935'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b8cf4ab3-03ca-460a-b42f-138e941008b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "व\n"
     ]
    }
   ],
   "source": [
    "print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04a26b49-67ac-4206-a791-1f9629ecffc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'वी'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char = '\\u0935\\u0940'\n",
    "char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7fee844b-4af6-4fb4-8a48-c464ea0f8ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2357"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('व')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "abd358b0-b6d8-47d8-b7d4-a9288c995f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'श'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(2358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39a79ad5-8cd9-482d-853e-e554632c44f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'व'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0x935)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "76f6123a-6533-482c-b2fc-01b2a6b54b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof('व')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abd0944c-878c-4557-82d7-ebed8917a08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'तुषार कुटे'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37c8dc9b-eb2c-4843-a516-59b3cdbcb717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['तुषार', 'कुटे']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cc1d188f-3d94-448d-a707-d9441be202de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.startswith('त')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "affc1b48-63d8-4e4f-8c9e-b4f9d9ba0b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'तूषार कुटे'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.replace('तु','तू')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "03d73303-4f82-41dd-afd9-f9924dfc76bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.find('ष')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2280dc21-1229-4798-b997-4d02ed0c4888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6347a825-8ee4-4482-9392-d4fb595e62a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['प्रणव', 'अमेय', 'प्रतीक्षा', 'मिताली', 'ऋतुजा', 'रूथ', 'श्वेता']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0999d8a6-3ed9-4748-aa1c-af4bb898e7dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "प्रणव\n",
      "प्रतीक्षा\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    if name.startswith('प्र'):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "20975c90-99e6-4111-beef-b0e77fb7d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtext = '४८ कि. मी. अंतरावर आणि पुणे जिल्ह्यातील वेल्हे तालुक्यात व भोर गावाच्या वायव्येला २४ कि.मी. अंतरावर नीरा-वेळवंडी-कानंदी आणि गुंजवणी या नद्यांच्या खोऱ्यांच्या बेचक्यात मुरुंबदेवाचा डोंगर उभा आहे. मावळ भागामध्ये राज्यविस्तार साध्य करण्यासाठी राजगड आणि तोरणा हे दोन्ही किल्ले मोक्याच्या ठिकाणी होते. तोरणा Archived 2020-09-20 at the Wayback Machine. किल्ल्याचा बालेकिल्ला आकाराने लहान असल्यामुळे राजकीय केंद्र म्हणून हा किल्ला सोयीचा नव्हता. त्यामानाने राजगड दुर्गम असून त्याचा बालेकिल्ला बराच मोठा आहे.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bc74f8df-6c63-41ba-9195-9e3786b9f825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'४८ कि. मी. अंतरावर आणि पुणे जिल्ह्यातील वेल्हे तालुक्यात व भोर गावाच्या वायव्येला २४ कि.मी. अंतरावर नीरा-वेळवंडी-कानंदी आणि गुंजवणी या नद्यांच्या खोऱ्यांच्या बेचक्यात मुरुंबदेवाचा डोंगर उभा आहे. मावळ भागामध्ये राज्यविस्तार साध्य करण्यासाठी राजगड आणि तोरणा हे दोन्ही किल्ले मोक्याच्या ठिकाणी होते. तोरणा Archived 2020-09-20 at the Wayback Machine. किल्ल्याचा बालेकिल्ला आकाराने लहान असल्यामुळे राजकीय केंद्र म्हणून हा किल्ला सोयीचा नव्हता. त्यामानाने राजगड दुर्गम असून त्याचा बालेकिल्ला बराच मोठा आहे.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8fc3a32-31b6-4283-8df4-a3af8c4b2cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['४८',\n",
       " 'कि',\n",
       " '.',\n",
       " 'मी',\n",
       " '.',\n",
       " 'अंतरावर',\n",
       " 'आणि',\n",
       " 'पुणे',\n",
       " 'जिल्ह्यातील',\n",
       " 'वेल्हे',\n",
       " 'तालुक्यात',\n",
       " 'व',\n",
       " 'भोर',\n",
       " 'गावाच्या',\n",
       " 'वायव्येला',\n",
       " '२४',\n",
       " 'कि.मी',\n",
       " '.',\n",
       " 'अंतरावर',\n",
       " 'नीरा-वेळवंडी-कानंदी',\n",
       " 'आणि',\n",
       " 'गुंजवणी',\n",
       " 'या',\n",
       " 'नद्यांच्या',\n",
       " 'खोऱ्यांच्या',\n",
       " 'बेचक्यात',\n",
       " 'मुरुंबदेवाचा',\n",
       " 'डोंगर',\n",
       " 'उभा',\n",
       " 'आहे',\n",
       " '.',\n",
       " 'मावळ',\n",
       " 'भागामध्ये',\n",
       " 'राज्यविस्तार',\n",
       " 'साध्य',\n",
       " 'करण्यासाठी',\n",
       " 'राजगड',\n",
       " 'आणि',\n",
       " 'तोरणा',\n",
       " 'हे',\n",
       " 'दोन्ही',\n",
       " 'किल्ले',\n",
       " 'मोक्याच्या',\n",
       " 'ठिकाणी',\n",
       " 'होते',\n",
       " '.',\n",
       " 'तोरणा',\n",
       " 'Archived',\n",
       " '2020-09-20',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Wayback',\n",
       " 'Machine',\n",
       " '.',\n",
       " 'किल्ल्याचा',\n",
       " 'बालेकिल्ला',\n",
       " 'आकाराने',\n",
       " 'लहान',\n",
       " 'असल्यामुळे',\n",
       " 'राजकीय',\n",
       " 'केंद्र',\n",
       " 'म्हणून',\n",
       " 'हा',\n",
       " 'किल्ला',\n",
       " 'सोयीचा',\n",
       " 'नव्हता',\n",
       " '.',\n",
       " 'त्यामानाने',\n",
       " 'राजगड',\n",
       " 'दुर्गम',\n",
       " 'असून',\n",
       " 'त्याचा',\n",
       " 'बालेकिल्ला',\n",
       " 'बराच',\n",
       " 'मोठा',\n",
       " 'आहे',\n",
       " '.']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(mtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794a61db-1fb8-43a2-b88f-f574079d20d5",
   "metadata": {},
   "source": [
    "##### Space Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ba279974-0a62-4240-9ba5-028c1e22410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('mydata.txt')\n",
    "data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4610503b-4684-4316-983a-ca412c467be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends! How are you?\n",
      "Welcome to the world of Python Programming.\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "04aee550-8dc4-46bb-aa6a-ab000dd8ffa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you?\\nWelcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'Programming.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "from nltk.tokenize import SpaceTokenizer\n",
    "\n",
    "# create the object\n",
    "tk = SpaceTokenizer()\n",
    "\n",
    "# tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8dbc6f4-8de4-4941-adfa-ee31c4f87334",
   "metadata": {},
   "source": [
    "##### Tab Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0321a13b-9ae3-4881-a37e-10f6dd2e80fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends!\tHow are you?\n",
      "Welcome to the world of\tPython Programming.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('mydata.txt')\n",
    "data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b7d21dde-5368-4fa6-92ab-377c01de7154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Friends!',\n",
       " 'How are you?\\nWelcome to the world of',\n",
       " 'Python Programming.\\n']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "from nltk.tokenize import TabTokenizer\n",
    "\n",
    "# create the object\n",
    "tk = TabTokenizer()\n",
    "\n",
    "# tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c413f123-7996-45a0-84b7-0450a2af3ced",
   "metadata": {},
   "source": [
    "##### Line Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4ab85e8b-9fb0-4e80-bc46-0923e7866dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello Friends!\\tHow are you?',\n",
       " 'Welcome to the world of\\tPython Programming.']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "from nltk.tokenize import LineTokenizer\n",
    "\n",
    "# create the object\n",
    "tk = LineTokenizer()\n",
    "\n",
    "# tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb6c040-476d-4bd2-b4d8-45155c15482c",
   "metadata": {},
   "source": [
    "##### Whitespace Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d4315ccc-dd64-43af-b37c-b7d1f9626514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'Programming.']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "# create the object\n",
    "tk = WhitespaceTokenizer()\n",
    "\n",
    "# tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa212dd0-2356-42e1-846a-5ad871cc58ef",
   "metadata": {},
   "source": [
    "##### MWE Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e772e34b-7a07-4f46-a293-f0eadc551e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = '''The Van Rossum is Python creator, visting Pune this week. The \n",
    "development community is very eager to meet Van Rossum.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1b0e68c2-6539-4120-940e-83b3b8e25e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Van Rossum is Python creator, visting Pune this week. The \n",
      "development community is very eager to meet Van Rossum.\n"
     ]
    }
   ],
   "source": [
    "print(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f3724289-d329-4ece-9bd3-c0ae138bfda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Van',\n",
       " 'Rossum',\n",
       " 'is',\n",
       " 'Python',\n",
       " 'creator',\n",
       " ',',\n",
       " 'visting',\n",
       " 'Pune',\n",
       " 'this',\n",
       " 'week',\n",
       " '.',\n",
       " 'The',\n",
       " 'development',\n",
       " 'community',\n",
       " 'is',\n",
       " 'very',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'Van',\n",
       " 'Rossum',\n",
       " '.']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3b171f2c-5ed3-4719-b1f4-5859dfc3f266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Van Rossum',\n",
       " 'is',\n",
       " 'Python',\n",
       " 'creator',\n",
       " ',',\n",
       " 'visting',\n",
       " 'Pune',\n",
       " 'this',\n",
       " 'week',\n",
       " '.',\n",
       " 'The',\n",
       " 'development',\n",
       " 'community',\n",
       " 'is',\n",
       " 'very',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'Van Rossum',\n",
       " '.']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "from nltk.tokenize import MWETokenizer\n",
    "\n",
    "# create the object\n",
    "tk = MWETokenizer(separator=' ')\n",
    "\n",
    "# add Multi Word Expression\n",
    "tk.add_mwe(('Van','Rossum'))\n",
    "\n",
    "# tokenize the data\n",
    "tk.tokenize(word_tokenize(sent1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d93ed2-2b69-4f55-b494-98971a2f52b3",
   "metadata": {},
   "source": [
    "##### Tweet Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "87e5e447-db71-4841-b296-3b96c819bb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'Hello Friends :)! How are you? Welcome to the world of Python Programming. :D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4d317f67-7f83-4345-a5c0-ce7ce5dce83b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends :)! How are you? Welcome to the world of Python Programming. :D\n"
     ]
    }
   ],
   "source": [
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "933068c9-b9ef-43ea-bb94-bba262d69523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends',\n",
       " ':)',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " '.',\n",
       " ':D']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the class\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# create the object\n",
    "tk = TweetTokenizer()\n",
    "\n",
    "# tokenize the data\n",
    "tk.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8b09ba7a-c86c-4d82-8ebc-6d09963d1a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends!😀 How are you?👋\n",
      "Welcome🙏🏼 to the world🌎 of Python 💻Programming.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('mydata.txt', encoding='utf-8')\n",
    "data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "17468ba6-82c8-4c51-a883-6a8012514fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends',\n",
       " '!',\n",
       " '😀',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " '👋',\n",
       " 'Welcome🙏🏼',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world🌎',\n",
       " 'of',\n",
       " 'Python',\n",
       " '💻Programming',\n",
       " '.']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "638aba6a-0c34-4594-9adc-d9533241b7cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends',\n",
       " '!',\n",
       " '😀',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " '👋',\n",
       " 'Welcome',\n",
       " '🙏🏼',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " '🌎',\n",
       " 'of',\n",
       " 'Python',\n",
       " '💻',\n",
       " 'Programming',\n",
       " '.']"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029cac4f-d5d9-4bae-b648-6ad688e5795a",
   "metadata": {},
   "source": [
    "##### Custom Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a5ac0e87-f53d-4425-8b03-167e49e33143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:\n",
      "This\n",
      "is\n",
      "some\n",
      "text\n",
      "with\n",
      "punctuation\n",
      ">\n",
      "Let's\n",
      "tokenize\n",
      "it\n",
      "Is\n",
      "it\n",
      "ok\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def custom_tokenizer(text):\n",
    "    return re.split(r\"[.,;?!\\s]+\", text)\n",
    "\n",
    "text = \"This is some text with punctuation > Let's tokenize it. Is it ok?\"\n",
    "\n",
    "tokens = custom_tokenizer(text)\n",
    "\n",
    "print(\"Tokens:\")\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ecfeddaa-a215-4665-9311-d58ba2ab5162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://mitu.co.in/dataset\n",
    "# Download: student3.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4147f76c-13f3-4219-af8c-f81fc40dabbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('student3.tsv')\n",
    "data = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8842e435-2eb0-4214-8174-9767cb3ce8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roll\tname\tclass\tmarks\tage\n",
      "1\tanil\tTE\t56.77\t22\n",
      "2\tamit\tTE\t59.77\t21\n",
      "3\taniket\tBE\t76.88\t19\n",
      "4\tajinkya\tTE\t69.66\t20\n",
      "5\tasha\tTE\t63.28\t20\n",
      "6\tayesha\tBE\t49.55\t20\n",
      "7\tamar\tBE\t65.34\t19\n",
      "8\tamita\tBE\t68.33\t23\n",
      "9\tamol\tTE\t56.75\t20\n",
      "10\tanmol\tBE\t78.66\t21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ba8f7825-242d-4c69-94ec-d49687ae3b12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['roll', 'name', 'class', 'marks', 'age'],\n",
       " [1, 'anil', 'TE', 56.77, 22],\n",
       " [2, 'amit', 'TE', 59.77, 21],\n",
       " [3, 'aniket', 'BE', 76.88, 19],\n",
       " [4, 'ajinkya', 'TE', 69.66, 20],\n",
       " [5, 'asha', 'TE', 63.28, 20],\n",
       " [6, 'ayesha', 'BE', 49.55, 20],\n",
       " [7, 'amar', 'BE', 65.34, 19],\n",
       " [8, 'amita', 'BE', 68.33, 23],\n",
       " [9, 'amol', 'TE', 56.75, 20],\n",
       " [10, 'anmol', 'BE', 78.66, 21],\n",
       " ['']]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdata = []\n",
    "for x in data.split('\\n'):\n",
    "    inner_list = []\n",
    "    for y in x.split('\\t'):\n",
    "        if y.isdigit():\n",
    "            inner_list.append(int(y))\n",
    "        elif y.find('.') > 0:\n",
    "            inner_list.append(float(y))\n",
    "        else:\n",
    "            inner_list.append(y)\n",
    "    newdata.append(inner_list)\n",
    "newdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2cbeb4-978b-4013-82a5-caa0a99f169e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
